Module llmreflect.Agents.BasicAgent
===================================

Classes
-------

`Agent(prompt: llmreflect.Prompt.BasicPrompt.BasicPrompt, llm: langchain.schema.language_model.BaseLanguageModel)`
:   Abstract class for agent, in this design each agent should have
    a retriever, retriever is for retrieving the final result based
    on the gross output by LLM.
    For example, a database retriever does the following job:
    extract the sql command from the llm output and then
    execute the command in the database.
    
    Create a new model by parsing and validating input data from keyword arguments.
    
    Raises ValidationError if the input data cannot be parsed to form a valid model.

    ### Ancestors (in MRO)

    * langchain.chains.llm.LLMChain
    * langchain.chains.base.Chain
    * langchain.load.serializable.Serializable
    * pydantic.main.BaseModel
    * pydantic.utils.Representation
    * abc.ABC

    ### Descendants

    * llmreflect.Agents.BasicAgent.OpenAIAgent

    ### Static methods

    `equip_retriever(retriever: llmreflect.Retriever.BasicRetriever.BasicRetriever)`
    :

    ### Methods

    `generate(self, input_list: List[Dict[str, Any]], run_manager: Optional[langchain.callbacks.manager.CallbackManagerForChainRun] = None) ‑> langchain.schema.output.LLMResult`
    :   The core function for generating LLM result from inputs.
        By using the "check_current_openai_balance". The generation
        will be stopped when the cost is going to exceed the budget.

    `get_inputs(self) ‑> List[str]`
    :   showing inputs for the prompt template being used
        Returns:
            List: a list of strings

    `predict(self, **kwargs: Any) ‑> str`
    :   The llm prediction interface.
        Returns:
            str: The output / completion generated by llm.

`LLM_BACKBONE_MODEL()`
:   LLM names used for referencing

    ### Class variables

    `ada`
    :

    `babbage`
    :

    `code_cushman_001`
    :

    `code_cushman_002`
    :

    `code_davinci_001`
    :

    `code_davinci_002`
    :

    `curie`
    :

    `davinci`
    :

    `gpt_3_5_turbo`
    :

    `gpt_3_5_turbo_0301`
    :

    `gpt_3_5_turbo_0613`
    :

    `gpt_3_5_turbo_16k`
    :

    `gpt_3_5_turbo_16k_0613`
    :

    `gpt_4`
    :

    `gpt_4_0314`
    :

    `gpt_4_0613`
    :

    `gpt_4_32k`
    :

    `gpt_4_32k_0314`
    :

    `gpt_4_32k_0613`
    :

    `text_ada_001`
    :

    `text_babbage_001`
    :

    `text_curie_001`
    :

    `text_davinci_002`
    :

    `text_davinci_003`
    :

`OpenAIAgent(open_ai_key: str, prompt_name: str = '', max_output_tokens: int = 512, temperature: float = 0.0, llm_model='gpt-3.5-turbo')`
:   Agent class specifically designed for openAI.
    
    Create a new model by parsing and validating input data from keyword arguments.
    
    Raises ValidationError if the input data cannot be parsed to form a valid model.

    ### Ancestors (in MRO)

    * llmreflect.Agents.BasicAgent.Agent
    * langchain.chains.llm.LLMChain
    * langchain.chains.base.Chain
    * langchain.load.serializable.Serializable
    * pydantic.main.BaseModel
    * pydantic.utils.Representation
    * abc.ABC

    ### Descendants

    * llmreflect.Agents.DatabaseAgent.DatabaseAgent
    * llmreflect.Agents.EvaluationAgent.DatabaseGradingAgent
    * llmreflect.Agents.ModerateAgent.DatabaseModerateAgent
    * llmreflect.Agents.QuestionAgent.DatabaseQuestionAgent

    ### Static methods

    `equip_retriever(retriever: llmreflect.Retriever.BasicRetriever.BasicRetriever)`
    :

    ### Methods

    `get_inputs(self) ‑> List[str]`
    :   showing inputs for the prompt template being used
        Returns:
            List: A list of input variable, each one should be str